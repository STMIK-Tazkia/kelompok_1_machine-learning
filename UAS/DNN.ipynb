{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd1824c",
   "metadata": {},
   "source": [
    "# Klasifikasi Kismis Menggunakan Deep Neural Network (DNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50749481",
   "metadata": {},
   "source": [
    "Proyek ini bertujuan untuk mengklasifikasikan jenis kismis (Besni dan Kecimen) berdasarkan fitur fitur morfologi menggunakan model Deep Neural Network (DNN) dan TensorFlow/Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f4cf07",
   "metadata": {},
   "source": [
    "1. Persiapan Data\n",
    "\n",
    "Pada tahap ini, kita memuat dataset, mengubah label teks menjadi angka, dan melakukan penskalaan fitur agar model saraf (neural network) dapat memproses data dengan lebih stabil.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# Memuat dataset\n",
    "df = pd.read_csv('Raisin.csv')\n",
    "\n",
    "# Memisahkan fitur (X) dan target (y)\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Mengubah label teks (Besni/Kecimen) menjadi 0/1\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Standarisasi data agar memiliki rata-rata 0 dan varians 1\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Pembagian data: 80% Training, 20% Testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e99c34",
   "metadata": {},
   "source": [
    "2. Membangun Arsitektur DNN\n",
    "\n",
    "Kita menggunakan model sekuensial dengan teknik Batch Normalization (untuk mempercepat konvergensi) dan Dropout (untuk mencegah overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3fced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    # Input Layer & Hidden Layer 1\n",
    "    layers.Dense(89, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Hidden Layer 2\n",
    "    layers.Dense(55, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    # Output Layer (Sigmoid cocok untuk klasifikasi biner)\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8f9db",
   "metadata": {},
   "source": [
    "3. Pelatihan Model (Training)\n",
    "\n",
    "Menggunakan Early Stopping untuk menghentikan pelatihan jika tingkat kerugian (loss) pada data validasi tidak membaik selama 10 epoch berturut-turut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e449011",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"Memulai Pelatihan DNN...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=36,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2, # Mengambil 20% dari data train untuk validasi internal\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb5ed1e",
   "metadata": {},
   "source": [
    "4. Evaluasi dan Visualisasi\n",
    "\n",
    "Bagian ini menampilkan performa model dalam bentuk angka akurasi dan grafik visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi data test\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# Print Laporan Akurasi\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(\"\\n\" + \"~\" * 40)\n",
    "print(f\" >\\\\< Akurasi Model DNN: {accuracy:.2f}% >\\\\< \")\n",
    "print(\"~\" * 40 + \"\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# --- VISUALISASI ---\n",
    "\n",
    "#  Confusion Matrix\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix: Prediksi vs Aktual')\n",
    "plt.xlabel('Prediksi')\n",
    "plt.ylabel('Kenyataan')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
